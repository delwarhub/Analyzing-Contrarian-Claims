{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a CARDS classifier with RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Author: Mirjam Nanko\n",
    "## Date Created: 2021-02-01\n",
    "## Email: m.nanko@exeter.ac.uk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use GPU 0: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# Load the required packages\n",
    "\n",
    "# Dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# Regular expressions\n",
    "import re\n",
    "\n",
    "# Unidecoder\n",
    "import unicodedata\n",
    "\n",
    "# Timestamp / time measurment\n",
    "import time\n",
    "\n",
    "# Simpletransformers classifier\n",
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "# Label encode\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Model performance scores\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "# PyTorch: enable GPU access\n",
    "import torch\n",
    "\n",
    "# If you want to select a specific GPU, set it here:\n",
    "# gpu = 0\n",
    "# torch.cuda.set_device(gpu) \n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use GPU {}:'.format(torch.cuda.current_device()), torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define required functions\n",
    "\n",
    "# Define additional model performance scores (F1)\n",
    "def f1_multiclass_macro(labels, preds):\n",
    "    return f1_score(labels, preds, average='macro')\n",
    "def f1_multiclass_micro(labels, preds):\n",
    "    return f1_score(labels, preds, average='micro')\n",
    "def f1_multiclass_weighted(labels, preds):\n",
    "    return f1_score(labels, preds, average='weighted')\n",
    "def f1_class(labels, preds):\n",
    "    return f1_score(labels, preds, average=None)\n",
    "def precision(labels, preds):\n",
    "    return precision_score(labels, preds, average='macro')\n",
    "def recall(labels, preds):\n",
    "    return recall_score(labels, preds, average='macro')\n",
    "\n",
    "# Define text pre-processing functions\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "def remove_non_ascii(text):\n",
    "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
    "    return unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "def strip_underscores(text):\n",
    "    return re.sub(r'_+', ' ', text)\n",
    "def remove_multiple_spaces(text):\n",
    "    return re.sub(r'\\s{2,}', ' ', text)\n",
    "\n",
    "# Merge text pre-processing functions\n",
    "def denoise_text(text):\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_non_ascii(text)\n",
    "    text = strip_underscores(text)\n",
    "    text = remove_multiple_spaces(text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and pre-process the text data\n",
    "\n",
    "# Load the data\n",
    "train = pd.read_csv('training/train.csv').rename(columns={\"claim\": \"labels_orig\"})\n",
    "valid = pd.read_csv('training/valid.csv').rename(columns={\"claim\": \"labels_orig\"})\n",
    "test = pd.read_csv('training/test.csv').rename(columns={\"claim\": \"labels_orig\"})\n",
    "\n",
    "# Pre-process the text\n",
    "train['text'] = train['text'].astype(str).apply(denoise_text)\n",
    "valid['text'] = valid['text'].astype(str).apply(denoise_text)\n",
    "test['text'] = test['text'].astype(str).apply(denoise_text)\n",
    "\n",
    "# Load the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the labels\n",
    "train['labels'] = label_encoder.fit_transform(train.labels_orig)\n",
    "valid['labels'] = label_encoder.fit_transform(valid.labels_orig)\n",
    "test['labels'] = label_encoder.fit_transform(test.labels_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels_orig</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What do you do if you are a global warming ala...</td>\n",
       "      <td>5_1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2.) A sun-blocking volcanic aerosols componen...</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Now, I am very interested in the AMO, since it...</td>\n",
       "      <td>1_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Christy addressed recent challenges to the...</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After a brief protest from Massachusetts Repub...</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23431</th>\n",
       "      <td>Mrner and Parker conclude that the Fremantle t...</td>\n",
       "      <td>1_6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23432</th>\n",
       "      <td>Siegel, Jeremy J., The Concise Encyclopedia of...</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23433</th>\n",
       "      <td>According to Goklany's careful empirical analy...</td>\n",
       "      <td>0_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23434</th>\n",
       "      <td>In light of these several findings, it can rea...</td>\n",
       "      <td>4_4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23435</th>\n",
       "      <td>Truth n 16 The trace gases absorb the radiatio...</td>\n",
       "      <td>2_3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23436 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text labels_orig  labels\n",
       "0      What do you do if you are a global warming ala...         5_1      16\n",
       "1      (2.) A sun-blocking volcanic aerosols componen...         0_0       0\n",
       "2      Now, I am very interested in the AMO, since it...         1_1       1\n",
       "3      Dr. Christy addressed recent challenges to the...         0_0       0\n",
       "4      After a brief protest from Massachusetts Repub...         0_0       0\n",
       "...                                                  ...         ...     ...\n",
       "23431  Mrner and Parker conclude that the Fremantle t...         1_6       5\n",
       "23432  Siegel, Jeremy J., The Concise Encyclopedia of...         0_0       0\n",
       "23433  According to Goklany's careful empirical analy...         0_0       0\n",
       "23434  In light of these several findings, it can rea...         4_4      14\n",
       "23435  Truth n 16 The trace gases absorb the radiatio...         2_3       8\n",
       "\n",
       "[23436 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16,  0,  1,  7, 14, 11, 12, 13,  6, 10,  4, 17,  8, 15,  5,  3,  2,\n",
       "        9])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0_0': 0, '1_1': 1, '1_2': 2, '1_3': 3, '1_4': 4, '1_6': 5, '1_7': 6, '2_1': 7, '2_3': 8, '3_1': 9, '3_2': 10, '3_3': 11, '4_1': 12, '4_2': 13, '4_4': 14, '4_5': 15, '5_1': 16, '5_2': 17}\n"
     ]
    }
   ],
   "source": [
    "le_name_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(le_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Weights creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "0     0.70\n",
      "16    0.06\n",
      "17    0.04\n",
      "7     0.03\n",
      "4     0.02\n",
      "6     0.02\n",
      "8     0.01\n",
      "10    0.01\n",
      "1     0.01\n",
      "12    0.01\n",
      "11    0.01\n",
      "14    0.01\n",
      "3     0.01\n",
      "9     0.01\n",
      "13    0.01\n",
      "5     0.01\n",
      "15    0.01\n",
      "2     0.01\n",
      "Name: proportion, dtype: float64\n",
      "[0.9482884195193008, 0.0798675009201325, 3.90990990990991, 1.6522842639593909, 5.314285714285714, 4.030959752321982, 3.9695121951219514, 6.852631578947369, 3.0491803278688523, 3.863501483679525, 2.6956521739130435, 1.2840236686390532, 3.84070796460177, 7.153846153846154, 6.888888888888889, 5.685589519650655, 8.857142857142858, 6.2898550724637685]\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of categories\n",
    "print(round(train.labels.value_counts(normalize=True),2))\n",
    "# Calculate weights\n",
    "weights = compute_class_weight(class_weight='balanced', classes= train.labels.unique(), y=train.labels)\n",
    "weights = [*weights]\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31eb4a5871e4cb8a0c324241aec803f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23436 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620f34d461b14b6a9f652f38e53b4088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ad7b0300224838900a94083c0878e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/3907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752d376f827648feb05a5cc1b242e3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/3907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b67a9dfd4ee49ac87c9e95df514f4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 3:   0%|          | 0/3907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 42min 40s, sys: 3min 33s, total: 1h 46min 13s\n",
      "Wall time: 1h 47min 45s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11721,\n",
       " defaultdict(list,\n",
       "             {'global_step': [3907, 7814, 11721],\n",
       "              'train_loss': [0.004569053649902344,\n",
       "               0.0010551713639870286,\n",
       "               0.008465169928967953],\n",
       "              'mcc': [0.6919310410498666,\n",
       "               0.7193987797589124,\n",
       "               0.7539247258975573],\n",
       "              'f1_macro': [0.698093010076865,\n",
       "               0.7419281816247714,\n",
       "               0.7721193478866935],\n",
       "              'f1_micro': [0.83531669865643,\n",
       "               0.8395393474088292,\n",
       "               0.8690978886756238],\n",
       "              'f1_weighted': [0.8395721691375037,\n",
       "               0.849336173530304,\n",
       "               0.8721242638620107],\n",
       "              'acc': [0.83531669865643,\n",
       "               0.8395393474088292,\n",
       "               0.8690978886756238],\n",
       "              'f1_class': [array([0.90739167, 0.64516129, 0.64516129, 0.74576271, 0.63576159,\n",
       "                      0.86363636, 0.81553398, 0.71856287, 0.7012987 , 0.63636364,\n",
       "                      0.85365854, 0.95774648, 0.51282051, 0.37931034, 0.61818182,\n",
       "                      0.66666667, 0.71720117, 0.54545455]),\n",
       "               array([0.90569343, 0.81690141, 0.70967742, 0.82142857, 0.8       ,\n",
       "                      0.90909091, 0.79591837, 0.72815534, 0.72289157, 0.70833333,\n",
       "                      0.85714286, 0.97142857, 0.53763441, 0.50980392, 0.57142857,\n",
       "                      0.69565217, 0.71590909, 0.57761733]),\n",
       "               array([0.92259887, 0.90410959, 0.8       , 0.82142857, 0.8       ,\n",
       "                      0.9047619 , 0.84615385, 0.78125   , 0.74358974, 0.73913043,\n",
       "                      0.88607595, 0.97142857, 0.525     , 0.5106383 , 0.61538462,\n",
       "                      0.72340426, 0.73652695, 0.66666667])],\n",
       "              'eval_loss': [0.8283940211490348,\n",
       "               0.8518086058061777,\n",
       "               1.0783989347789127]}))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create a ClassificationModel\n",
    "model = ClassificationModel('roberta', 'roberta-large', \n",
    "                            num_labels = 18, weight = weights,\n",
    "                            args={'reprocess_input_data': True, \n",
    "                                  'overwrite_output_dir': False,\n",
    "                                  'output_dir': 'models/new_model/',\n",
    "                                  'best_model_dir': 'models/new_model/best_model/',\n",
    "                                  # Hyperparameters\n",
    "                                  'train_batch_size': 6,\n",
    "                                  'num_train_epochs': 3, \n",
    "                                  'learning_rate': 1e-5,\n",
    "                                  # Text processing\n",
    "                                  'max_seq_length': 256,\n",
    "                                  'sliding_window': True,\n",
    "                                  'stride': 0.6,\n",
    "                                  'do_lower_case': False,\n",
    "                                  # Evaluation\n",
    "                                  'evaluate_during_training': True,\n",
    "                                  'evaluate_during_training_verbose': True,\n",
    "                                  'evaluate_during_training_steps': -1,\n",
    "                                  # Saving\n",
    "                                  'save_model_every_epoch': True,\n",
    "                                  'save_eval_checkpoints': True,\n",
    "                                  'weight_decay': 0\n",
    "                                  })\n",
    "\n",
    "# Train and evaluate the model\n",
    "model.train_model(train, eval_df = valid,\n",
    "                  f1_macro = f1_multiclass_macro, \n",
    "                  f1_micro = f1_multiclass_micro, \n",
    "                  f1_weighted = f1_multiclass_weighted, \n",
    "                  acc = accuracy_score, \n",
    "                  f1_class = f1_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## RoBERTa classifier performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e75564570a14a3db7ea29b90b96c878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2605 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7080ba4b3d834173a5419c3815422951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "These are the results when testing the model on the validation data set:\n",
      "\n",
      "{'mcc': 0.7539247258975573, 'f1_macro': 0.7721193478866935, 'precision': 0.7493412638868281, 'recall': 0.8022745001257632, 'acc': 0.8690978886756238, 'f1_micro': 0.8690978886756238, 'f1_weighted': 0.8721242638620107, 'f1_class': array([0.92259887, 0.90410959, 0.8       , 0.82142857, 0.8       ,\n",
      "       0.9047619 , 0.84615385, 0.78125   , 0.74358974, 0.73913043,\n",
      "       0.88607595, 0.97142857, 0.525     , 0.5106383 , 0.61538462,\n",
      "       0.72340426, 0.73652695, 0.66666667]), 'eval_loss': 1.0783989347789127}\n",
      "CPU times: user 51.8 s, sys: 1.36 s, total: 53.1 s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Evaluate the classifier performance on the validation data\n",
    "result, model_outputs, wrong_predictions = model.eval_model(valid, \n",
    "                                                            f1_macro = f1_multiclass_macro,\n",
    "                                                            precision = precision, \n",
    "                                                            recall = recall,\n",
    "                                                            acc = accuracy_score,\n",
    "                                                            f1_micro = f1_multiclass_micro, \n",
    "                                                            f1_weighted = f1_multiclass_weighted, \n",
    "                                                            f1_class = f1_class)\n",
    "\n",
    "print('\\n\\nThese are the results when testing the model on the validation data set:\\n')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380c60f94b2e496fa6e9f7b9f24d6ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2904 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1662 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1072 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (515 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (856 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (671 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c132de74fa44548ef8f2d170360bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "These are the results when testing the model on the testing data set:\n",
      "\n",
      "{'mcc': 0.778054540578735, 'f1_macro': 0.7736175971410385, 'precision': 0.7968518165578657, 'recall': 0.7568648091287078, 'acc': 0.865358126721763, 'f1_micro': 0.865358126721763, 'f1_weighted': 0.8615224032424584, 'f1_class': array([0.92556454, 0.73684211, 0.68421053, 0.80645161, 0.79136691,\n",
      "       0.87272727, 0.86614173, 0.8503937 , 0.70212766, 0.81632653,\n",
      "       0.86868687, 0.9375    , 0.56410256, 0.5862069 , 0.73972603,\n",
      "       0.70422535, 0.79638009, 0.67613636]), 'eval_loss': 0.9732772377070843}\n",
      "CPU times: user 1min, sys: 1.7 s, total: 1min 1s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Evaluate the classifier performance on the testing data\n",
    "result_test, model_outputs_test, wrong_predictions_test = model.eval_model(test, \n",
    "                                                                           f1_macro = f1_multiclass_macro,\n",
    "                                                                           precision = precision, \n",
    "                                                                           recall = recall,\n",
    "                                                                           acc = accuracy_score,\n",
    "                                                                           f1_micro = f1_multiclass_micro, \n",
    "                                                                           f1_weighted = f1_multiclass_weighted,\n",
    "                                                                           f1_class = f1_class)\n",
    "print('\\n\\nThese are the results when testing the model on the testing data set:\\n')\n",
    "print(result_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
